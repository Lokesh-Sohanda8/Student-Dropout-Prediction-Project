# ğŸ“ Student Dropout Prediction System

### End-to-End Machine Learning & Deployment Project

---

## ğŸ“Œ Project Overview

This project builds a complete **Machine Learning system** to predict student dropout risk using academic, demographic, and financial indicators.

The goal was not only high predictive performance, but also:

* âœ” Model stability
* âœ” Reduced feature complexity
* âœ” Deployment-ready architecture
* âœ” Practical academic decision support

The final system delivers:

* Dropout classification (High / Moderate / Low Risk)
* Probability of dropout
* Interactive Streamlit web interface

---

## ğŸ“Š Dataset

* Source: **UCI Machine Learning Repository**
* Domain: Higher Education Student Performance
* Initial Features: ~36â€“37 variables
* Final Optimized Features: 25 â†’ 15 â†’ Deployment subset

Dataset includes:

* Academic performance indicators
* Enrollment behavior
* Financial status
* Demographics
* Course information
* Economic indicators

---

## âš™ï¸ Project Workflow

### 1ï¸âƒ£ Data Exploration & Validation

* Structural inspection (`info`, `describe`)
* Missing value check
* Duplicate detection
* Logical consistency validation
* Statistical outlier analysis

ğŸ“Œ Important Insight:
Outliers were retained since they represented real-world academic behavior rather than data errors.

---

### 2ï¸âƒ£ Feature Engineering

* Binary encoding of target variable
* Course grouping into meaningful clusters:

  * STEM
  * Health
  * Business
  * Arts
  * Social Sciences
* One-hot encoding of grouped course categories
* Removal of redundant semester-level academic features

ğŸ“Œ Reason:
Reduce multicollinearity and improve interpretability.

---

### 3ï¸âƒ£ Feature Selection Strategy

Three model versions were developed:

* Full Feature Model (~36 features)
* Reduced 25 Feature Model
* Optimized 15 Feature Model

Feature importance extracted using Random Forest.

Observation:

> Performance degradation from 36 â†’ 15 features was minimal.

This justified feature reduction for deployment simplicity.

---

## ğŸ¤– Models Trained

* Logistic Regression
* Decision Tree
* Random Forest
* XGBoost
* CatBoost
* Support Vector Machine (SVC)
* Multi-Layer Perceptron

Evaluation Metrics:

* Accuracy
* Precision
* Recall
* **F1-score (Primary Metric)**
* ROC-AUC

F1-score was prioritized due to class imbalance.

---

## ğŸ”§ Hyperparameter Tuning

Each model was tuned using GridSearchCV or RandomizedSearchCV.

Examples:

**Random Forest**

* n_estimators
* max_depth
* min_samples_split
* min_samples_leaf

**XGBoost**

* learning_rate
* max_depth
* n_estimators
* subsample
* colsample_bytree

**Logistic Regression**

* Regularization (C)
* Penalty type

CatBoost was tuned separately due to sklearn compatibility.

---

## ğŸ† Final Model Selection

Final shortlisted models:

| Model           | CV F1      | Test F1    |
| --------------- | ---------- | ---------- |
| Random Forest   | 0.8598     | 0.8937     |
| XGBoost         | 0.8592     | 0.9054     |
| **Soft Voting** | **0.8610** | **0.9032** |

Although XGBoost achieved slightly higher test F1,
Soft Voting was selected due to:

* Best cross-validation performance
* Greater stability
* Reduced variance
* Better generalization consistency

Final Model: **Soft Voting Classifier**

---

## ğŸ“ˆ Evaluation Curves

The final model was evaluated using:

* ROC Curve (AUC â‰ˆ 0.96+)
* Precisionâ€“Recall Curve (AP â‰ˆ 0.88â€“0.91)

Precision-Recall curve was emphasized due to class imbalance.

---

## ğŸ’¾ Model Serialization

The final trained model was saved using:

```python
joblib.dump(voting_model, "voting_dropout_model.pkl", compress=('xz', 3))
```

Compression applied to reduce model size.

---

# ğŸš€ Deployment (Streamlit Web App)

An interactive web application was developed using **Streamlit**.

---

## ğŸ¯ Deployment Feature Selection

Although the model was trained on the full optimized feature set,
the UI was intentionally simplified to require only high-impact inputs:

* Age at Enrollment
* Admission Grade
* Tuition Fees Up to Date
* Scholarship Holder
* Debtor
* Gender
* Course Group

### Why These?

Feature importance analysis revealed strongest predictors were:

1. Academic readiness
2. Financial stability
3. Debt status
4. Course category

This ensured:

* Minimal user input
* Maximum predictive power
* Practical usability

Remaining required model features are auto-filled internally to preserve compatibility.

---

## ğŸ“Š Risk Categorization

Probability thresholds:

* **< 30% â†’ Low Risk**
* **30â€“60% â†’ Moderate Risk**
* **> 60% â†’ High Risk**

This improves interpretability beyond binary classification.

---

## ğŸ§  Key Insights

* Financial instability strongly correlates with dropout.
* Debtor status significantly increases dropout probability.
* Admission grade is a strong predictor of persistence.
* Academic grouping influences completion likelihood.
* Feature reduction improves deployability without harming performance.

---

## ğŸ›  Technologies Used

* Python
* scikit-learn
* XGBoost
* CatBoost
* Pandas / NumPy
* Matplotlib / Seaborn
* Streamlit
* Joblib

---

## ğŸ Final Outcome

This project successfully bridges:

**Machine Learning Engineering â†’ Real-World Academic Decision Support**

It demonstrates:

* Strong model experimentation
* Logical feature engineering
* Ensemble modeling
* Hyperparameter tuning
* Deployment-focused thinking
* Production-ready ML workflow

---

## ğŸ“Œ Future Improvements

* SHAP-based explainability
* Automated threshold tuning
* Model monitoring system
* Cloud deployment (Streamlit Cloud / AWS / Azure)
* REST API integration

---

## ğŸ‘¤ Author

- Name: Lokesh Sohanda
- Project Name: Student Dropout Prediction System
- Type: Machine Learning Project
- End-to-End Model + Deployment Implementation

---
